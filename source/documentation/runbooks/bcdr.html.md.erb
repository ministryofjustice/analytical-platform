---
owner_slack: "#analytical-platform-notifications"
title: Business continuity and disaster recovery
last_reviewed_on: 2025-12-03
review_in: 6 months
weight: 0
---

# <%= current_page.data.title %>

## Overview

This document outlines thge business continuity and disaster recovery (BCDR) processes for the Analytical Platform, as well as our appetite for risk in relation to the uptime and recoverability of the service.

## Steps to take

If an incident which requires full or partial platform recovery occurs, follow these steps:

- Communicate the issue - see the [section below](#communication-plan)
- Identify the cause
- Agree on recovery action(s)
- Update communications
- Perform recovery actions (or monitor external incident sources - see below)
- Verify that operations are restored
- Update communications
- Perform a post-incident review, identify actions and update runbooks if applicable (this can be done later)

### Issues with underlying platforms

If the cause is identified as being an incident or issue with Modernisation Platform (or Cloud Platform for user-deployed apps) then recovery will largely be out of the hands of this team. Monitor the [#ask-moderinsation-platform] (or [#ask-cloud-platform]) channel and [relay any relevant information](#communication-plan) to users.

If the issue is with underlying AWS infrastructure (an AWS outage) then monitor the relevant AWS incident page and relay information as above.

Once the underlying issue is resolved, perform manual checks of the availability of AP services before communicating the resolution to users.

## Communication plan

- **Internal Communication**:
  - Notify the Analytical Platform team immediately when a incident is identified via the [#analytical-platform] Slack channel.
  - Create an incident thread in the above channel and tag the team using the `@analytical-platform-team` tag (not `@here` or `@channel`)
- **External Communication**:
  - Inform users about any relevant service disruptions via the [#ask-analytical-plaform] Slack channel and user groups such as the #ask-data-engineering Slack channel or DEDS email group.

## Business appetite for time to recovery

A week?

### Data loss

In general data is owned by users of the platform, and we do not currently back up or replicate user data held in S3 buckets. In the event of data loss, data must be re-ingested or re-uploaded from the original sources.

We rely on the reliability of AWS S3 standard storage:

- Backed with the [Amazon S3 Service Level Agreement](https://aws.amazon.com/s3/sla/).
- Designed to provide 99.999999999% durability and 99.99% availability of objects over a given year.
- S3 Standard (... etc.) are all designed to sustain data in the event of the loss of an entire Amazon S3 Availability Zone.

([Source](https://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html))

Given the above we do not consider it cost effective to replicate or otherwise back up petabytes of data.

We do not guarantee protection against accidental deletion or modification of data by users. Accidental deletion does not contitute an incident or disaster in the context of this documument.

### Platform recovery

All infrastructure is defined in code, with the core of the platform being defined in the Modernisation Platform environments repository:

- [Common / core](https://github.com/ministryofjustice/modernisation-platform-environments/tree/main/terraform/environments/analytical-platform-common)
- [Compute](https://github.com/ministryofjustice/modernisation-platform-environments/tree/main/terraform/environments/analytical-platform-compute)
- [Ingestion](https://github.com/ministryofjustice/modernisation-platform-environments/tree/main/terraform/environments/analytical-platform-ingestion)

Terraform actions should be run in the order above.

### Data access

Data engineering data access repo can re-create project access, but the S3 paths could be different. IAM ARNS?

### Register My Data

Re-create - as above; paths and IAM roles ARNs could change

### Airflow and managed pipelines

Something here

### Create a Derived Table (CaDeT)

[CaDeT] is based on [dbt](https://www.getdbt.com/) where all workflows and derived data defintions are defined in code. Once source data has been re-ingested the models can be updated to reflect any changed S3 paths and re-run.

### Tooling

Recovery of CP and tooling

### User-defined code

Analysis code?

<!-- external links -->
[#ask-analytical-platform] : https://moj.enterprise.slack.com/archives/C4PF7QAJZ
[#analytical-platform] : https://moj.enterprise.slack.com/archives/C04M8224WCV
[#modernisation-platform-update] : https://moj.enterprise.slack.com/archives/C02L5MCJ12N
[#ask-moderinsation-platform]: https://moj.enterprise.slack.com/archives/C57UPMZLY
[#cloud-platform-update] : https://moj.enterprise.slack.com/archives/CH6D099DF
[#ask-cloud-platform]: https://moj.enterprise.slack.com/archives/C57UPMZLY
[CaDeT] : https://github.com/moj-analytical-services/create-a-derived-table/tree/main